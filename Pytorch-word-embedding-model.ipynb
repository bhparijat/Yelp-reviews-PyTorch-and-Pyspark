{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"model/master_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>text_length</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>total bill horrible service 8gs crooks actuall...</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>adore travis hard rocks new kelly cardenas sal...</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>1064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>say office really together organized friendly ...</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>went lunch steak sandwich delicious caesar sal...</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>today second three sessions paid although firs...</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  Q1sbwvVQXV2734tPgoKj4Q  hG7b0MtEbXx5QzbzE6C_VA  ujmEBvifdJM6h6RLv4wQIg   \n",
       "1  GJXCdrto3ASJOqKeVWPi6Q  yXQM5uF2jS6es16SJzNHfg  NZnhc2sEQy3RmzKTZnqtwQ   \n",
       "2  2TzJjDVDEuAW6MR5Vuc1ug  n6-Gk65cPZL6Uz8qRm3NYw  WTqjgwHlXbSFevF32_DJVw   \n",
       "3  yi0R0Ugj_xUx_Nek0-_Qig  dacAIZ6fTM6mqwW5uxkskg  ikCg8xy5JIg_NGPx-MSIDA   \n",
       "4  11a8sVPMUFtaC7_ABRkmtw  ssoyf2_x0EQMed6fgHeMyQ  b1b1eb3uo-w561D0ZfCEiQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      1       6      1     0   \n",
       "1      5       0      0     0   \n",
       "2      5       3      0     0   \n",
       "3      5       0      0     0   \n",
       "4      1       7      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  total bill horrible service 8gs crooks actuall...  2013-05-07 04:34:36   \n",
       "1  adore travis hard rocks new kelly cardenas sal...  2017-01-14 21:30:33   \n",
       "2  say office really together organized friendly ...  2016-11-09 20:09:03   \n",
       "3  went lunch steak sandwich delicious caesar sal...  2018-01-09 20:56:38   \n",
       "4  today second three sessions paid although firs...  2018-01-30 23:07:38   \n",
       "\n",
       "   text_length  label  \n",
       "0          129      0  \n",
       "1         1064      1  \n",
       "2          369      1  \n",
       "3          279      1  \n",
       "4         2021      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6685899, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_mod = reviews.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6685820, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_mod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.map_word = {}\n",
    "        self.map_index = {}\n",
    "        self.x_y_pairs = {}\n",
    "        self.pairs_map = {}\n",
    "        \n",
    "#    def word_embed(self)\n",
    "    \n",
    "#     def word2vec(self):\n",
    "#         self.window_size = 2\n",
    "#         self.epochs = 100\n",
    "#         self.embeddings = 10\n",
    "#         self.vocab_size = length(sla.pairs_map[self.window_size].keys())\n",
    "        \n",
    "#         weight1 = torch.randn(self.embeddings,self.vocab_size)\n",
    "#         weight2 = torch.randn(self.vocab_size,self.embeddings)\n",
    "        \n",
    "#         for epoch in epochs:\n",
    "#             for center,context in \n",
    "    \n",
    "    def NGRAM(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSelfEmbedding:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.window_size = 2\n",
    "        self.epochs = 100\n",
    "        self.embeddings = 10\n",
    "        self.epoch_loss = 0\n",
    "        \n",
    "    def train(self,pairs_map):\n",
    "        \n",
    "        self.vocab_size = len(sla.pairs_map[self.window_size])\n",
    "        \n",
    "        weight1 = torch.randn(self.embeddings,self.vocab_size).float()\n",
    "        weight2 = torch.randn(self.vocab_size,self.embeddings).float()\n",
    "        \n",
    "        print(self.vocab_size)\n",
    "        \n",
    "        for center,target in pairs_map[self.window_size]:\n",
    "            \n",
    "            inpt = torch.zeros(self.vocab_size).float()\n",
    "            inpt[center] = 1.0\n",
    "            z1 = torch.matmul(weight1,inpt)\n",
    "            z2 = torch.matmul(weight2,z1)\n",
    "            \n",
    "            log_output = torch.log_softmax(z2)\n",
    "            \n",
    "            loss = torch.nn.functional.nll_loss(log_output.view(1,-1),torch.tensor([context]))\n",
    "            \n",
    "            total_loss += loss\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_vocab(map_word,map_index,x):\n",
    "    \n",
    "    idx = len(map_word.keys())\n",
    "    ans = []\n",
    "    #print(type(x),x)\n",
    "    for word in x.split():\n",
    "        if word not in map_word:\n",
    "            idx+=1\n",
    "            map_word[word] = idx\n",
    "            map_index[idx] = word\n",
    "        ans.append(idx)\n",
    "            \n",
    "    return ans\n",
    "\n",
    "\n",
    "def build_context_center(x,pairs_map,window = 2):\n",
    "    \n",
    "    if window not in pairs_map:\n",
    "        pairs_map[window] = []\n",
    "        \n",
    "    #x = x.split()\n",
    "    for i in range(len(x)):\n",
    "        \n",
    "        for j in range(1,window+1):\n",
    "            \n",
    "            if (i-j)>0:\n",
    "                pairs_map[window].append([x[i],x[i-j]])\n",
    "                \n",
    "            if (i+j)<len(x):\n",
    "                pairs_map[window].append([x[i],x[i+j]])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 13s, sys: 3.12 s, total: 2min 16s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sla = SentimentAnalysis()\n",
    "reviews_mod['tokenized'] = reviews_mod.text.apply(lambda x: tokenize_vocab(sla.map_word,sla.map_index,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4755"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_mod.text_length.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 8s, sys: 1min 13s, total: 20min 21s\n",
      "Wall time: 20min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = reviews_mod.iloc[:,].tokenized.apply(lambda x:build_context_center(x,sla.pairs_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [2, 4],\n",
       " [3, 2],\n",
       " [3, 4],\n",
       " [3, 5],\n",
       " [4, 3],\n",
       " [4, 5],\n",
       " [4, 2]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sla.pairs_map[2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 46s, sys: 1min 36s, total: 16min 22s\n",
      "Wall time: 18min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle as pkl\n",
    "with open(\"model/map.pkl\",'wb') as file:\n",
    "    pkl.dump(sla.pairs_map,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.53 s, sys: 241 ms, total: 1.77 s\n",
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(\"model/map_word.pkl\",'wb') as file:\n",
    "    pkl.dump(sla.map_word,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 s, sys: 225 ms, total: 1.67 s\n",
      "Wall time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(\"model/map_index.pkl\",'wb') as file:\n",
    "    pkl.dump(sla.map_index,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_embedding = TrainSelfEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1475186332\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-49971dea3144>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, pairs_map)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0minpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0minpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "self_embedding.train(sla.pairs_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
